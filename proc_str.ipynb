{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desperate-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import tweepy\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "golden-transition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Todas as bica na canela do contra o Bayern! Felipe Jonathan saia do Santos '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tex='RT @desimpedidos: Todas as bica na canela do @oficialharielmc contra o Bayern! https://t.co/Z6FVPa1yZe @szkntos @SantosFC Felipe Jonathanüëãsaia do Santosüëãüëã'\n",
    "\n",
    "#remover os @ marcados no tweet\n",
    "tex=re.sub(r'@[aA-zZ]* ', '', tex, flags=re.MULTILINE)\n",
    "\n",
    "#remover dados quando √© RT\n",
    "tex=re.sub(r'RT @*[aA-zZ]*[0-9]*: ', '', tex, flags=re.MULTILINE)\n",
    "\n",
    "#remover links\n",
    "tex=re.sub(r'https:\\/\\/t.co\\/*[aA0-zZ9]* ', '', tex, flags=re.MULTILINE)\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "tex=emoji_pattern.sub(r' ', tex)\n",
    "\n",
    "\n",
    "tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "conceptual-award",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tbgdm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spare-sydney",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tbgdm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exact-fighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['de', 'a', 'o', 'que', 'e', '√©', 'do', 'da', 'em', 'um', 'para',\n",
       "       'com', 'n√£o', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as',\n",
       "       'dos', 'como', 'mas', 'ao', 'ele', 'das', '√†', 'seu', 'sua', 'ou',\n",
       "       'quando', 'muito', 'nos', 'j√°', 'eu', 'tamb√©m', 's√≥', 'pelo',\n",
       "       'pela', 'at√©', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo',\n",
       "       'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'voc√™', 'essa',\n",
       "       'num', 'nem', 'suas', 'meu', '√†s', 'minha', 'numa', 'pelos',\n",
       "       'elas', 'qual', 'n√≥s', 'lhe', 'deles', 'essas', 'esses', 'pelas',\n",
       "       'este', 'dele', 'tu', 'te', 'voc√™s', 'vos', 'lhes', 'meus',\n",
       "       'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos',\n",
       "       'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele',\n",
       "       'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'est√°',\n",
       "       'estamos', 'est√£o', 'estive', 'esteve', 'estivemos', 'estiveram',\n",
       "       'estava', 'est√°vamos', 'estavam', 'estivera', 'estiv√©ramos',\n",
       "       'esteja', 'estejamos', 'estejam', 'estivesse', 'estiv√©ssemos',\n",
       "       'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'h√°',\n",
       "       'havemos', 'h√£o', 'houve', 'houvemos', 'houveram', 'houvera',\n",
       "       'houv√©ramos', 'haja', 'hajamos', 'hajam', 'houvesse',\n",
       "       'houv√©ssemos', 'houvessem', 'houver', 'houvermos', 'houverem',\n",
       "       'houverei', 'houver√°', 'houveremos', 'houver√£o', 'houveria',\n",
       "       'houver√≠amos', 'houveriam', 'sou', 'somos', 's√£o', 'era', '√©ramos',\n",
       "       'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'f√¥ramos', 'seja',\n",
       "       'sejamos', 'sejam', 'fosse', 'f√¥ssemos', 'fossem', 'for', 'formos',\n",
       "       'forem', 'serei', 'ser√°', 'seremos', 'ser√£o', 'seria', 'ser√≠amos',\n",
       "       'seriam', 'tenho', 'tem', 'temos', 't√©m', 'tinha', 't√≠nhamos',\n",
       "       'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera',\n",
       "       'tiv√©ramos', 'tenha', 'tenhamos', 'tenham', 'tivesse',\n",
       "       'tiv√©ssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei',\n",
       "       'ter√°', 'teremos', 'ter√£o', 'teria', 'ter√≠amos', 'teriam'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lista de stopwords do nltk\n",
    "listaStop = nltk.corpus.stopwords.words('portuguese')\n",
    "np.transpose(listaStop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "coupled-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recebe a string splitada e retorna sem as stopwords que estiverem na frase\n",
    "def removeStopWords(text):\n",
    "    frase = []\n",
    "    i=0\n",
    "    while(i<len(text)):\n",
    "        if text[i] not in listaStop:\n",
    "            frase.append(text[i])\n",
    "        i=i+1\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "surprising-warrior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Todas',\n",
       " 'bica',\n",
       " 'canela',\n",
       " 'contra',\n",
       " 'Bayern!',\n",
       " 'Felipe',\n",
       " 'Jonathan',\n",
       " 'saia',\n",
       " 'Santos']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeStopWords(tex.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-remove",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
